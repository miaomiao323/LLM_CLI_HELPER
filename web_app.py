import streamlit as st
import requests
import os

# --- é…ç½®éƒ¨åˆ† ---
# é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="Linux å‘½ä»¤è¡ŒåŠ©æ‰‹", page_icon="ğŸ¤–")

st.title("ğŸ¤– AI å‘½ä»¤è¡ŒåŠ©æ‰‹")
st.caption("è¾“å…¥ä½ çš„éœ€æ±‚ï¼Œæˆ‘æ¥å¸®ä½ å†™å‘½ä»¤")

# è·å– API Key
# åœ¨æœ¬åœ°è¿è¡Œæ—¶ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–ï¼Œæˆ–è€…åœ¨é¡µé¢ä¾§è¾¹æ è¾“å…¥
api_key = os.getenv("API_KEY")

# å¦‚æœæ²¡æœ‰ç¯å¢ƒå˜é‡ï¼Œå…è®¸ç”¨æˆ·åœ¨ä¾§è¾¹æ è¾“å…¥
if not api_key:
    with st.sidebar:
        api_key = st.text_input("è¯·è¾“å…¥ SiliconFlow API Key", type="password")
        st.markdown("[å»ç”³è¯· Key](https://cloud.siliconflow.cn/)")

# API é…ç½®
API_BASE_URL = "https://api.siliconflow.cn/v1/chat/completions"
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---
def get_llm_response(prompt, key):
    headers = {
        "Authorization": f"Bearer {key}",
        "Content-Type": "application/json"
    }
    
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‘½ä»¤è¡Œ(CLI)åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šå‘Šè¯‰ä½ ä»–ä»¬æƒ³åšä»€ä¹ˆï¼Œä½ éœ€è¦æä¾›ç›¸åº”çš„ Linux/macOS å‘½ä»¤è¡ŒæŒ‡ä»¤ã€‚\n"
        "è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š\n"
        "1. å¦‚æœç”¨æˆ·æ„å›¾ä¸æ˜ç¡®ï¼Œè¯·ç»™å‡ºæœ€å¸¸ç”¨çš„å‘½ä»¤ã€‚\n"
        "2. å¦‚æœæ“ä½œæœ‰å±é™©ï¼ˆå¦‚ rm -rfï¼‰ï¼Œè¯·åœ¨è§£é‡Šä¸­æ˜ç¡®è­¦å‘Šã€‚\n"
        "3. è¾“å‡ºæ ¼å¼å¿…é¡»ä¸¥æ ¼å¦‚ä¸‹ï¼š\n"
        "```bash\n"
        "<æ­¤å¤„å†™å…·ä½“çš„å‘½ä»¤è¡ŒæŒ‡ä»¤>\n"
        "```\n"
        "è¯´æ˜ï¼š<æ­¤å¤„å†™ç®€çŸ­çš„ä¸­æ–‡è§£é‡Š>"
    )

    data = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "max_tokens": 512,
        "stream": False
    }

    try:
        response = requests.post(API_BASE_URL, headers=headers, json=data, timeout=30)
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            return f"API è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}"
    except Exception as e:
        return f"å‘ç”Ÿé”™è¯¯: {str(e)}"

# --- èŠå¤©ç•Œé¢é€»è¾‘ ---

# 1. åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ä½ å¥½ï¼è¯·å‘Šè¯‰æˆ‘ä½ æƒ³æ‰§è¡Œä»€ä¹ˆæ“ä½œï¼Ÿä¾‹å¦‚ï¼š'è§£å‹ tar.gz æ–‡ä»¶'"}]

# 2. æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 3. å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input():
    if not api_key:
        st.error("è¯·å…ˆé…ç½® API Key")
        st.stop()

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # è·å– AI å›å¤
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            response_text = get_llm_response(prompt, api_key)
            st.write(response_text)
    
    # ä¿å­˜ AI å›å¤åˆ°å†å²
    st.session_state.messages.append({"role": "assistant", "content": response_text})
